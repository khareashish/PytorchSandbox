{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch \n",
    "\n",
    "- Scientific computing package  \n",
    "- Replacement for NumPy to use the power of GPus \n",
    "- Deep learning research platform that provides maximum flexibility and speed \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors \n",
    "\n",
    "\n",
    "PyTorch uses **Tensor** as its core data structure, which is similar to Numpy array. Tensors provide acceleration of various mathematical operations. These operations when carried out in a large number in Deep Learning make a huge difference in speed.\n",
    "\n",
    "Tensor is simply a fancy name given to matrices. A scalar value is represented by a 0-dimensional Tensor. Similarly a column/row matrix using a 1-D Tensor and so on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([1., 3., 5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with just ones \n",
    "\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "\n",
    "\n",
    "# Create a tensor with just zeros \n",
    "\n",
    "b = torch.zeros(5)\n",
    "print(b)\n",
    "\n",
    "\n",
    "# Create a tensor with custom values\n",
    "\n",
    "c = torch.Tensor([1, 3, 5, 7, 9])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[[1., 2.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[5., 6.],\n",
      "         [7., 8.]]])\n"
     ]
    }
   ],
   "source": [
    "# Tensors of Higher dimension: \n",
    "\n",
    "# torch.zeros(Rows, Columns) \n",
    "d = torch.zeros(3,2)\n",
    "print(d)\n",
    "\n",
    "\n",
    "e = torch.ones(2,5)\n",
    "print(e)\n",
    "\n",
    "\n",
    "f = torch.tensor([[1.0, 2.0],[3.0, 4.0]])\n",
    "print(f)\n",
    "\n",
    "\n",
    "# 3D Tensor\n",
    "g = torch.tensor([[[1., 2.], [3., 4.]], [[5., 6.], [7., 8.]]])\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# find out shape of the tensor \n",
    "\n",
    "print(e.shape)\n",
    "\n",
    "print(f.shape)\n",
    " \n",
    "print(g.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing element in a 1D Tensor aka vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.)\n"
     ]
    }
   ],
   "source": [
    "print(c[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing element in a higher dimension Tensor \n",
    "\n",
    "To access one particular element in a tensor, we will need to specify indices equal to the dimension of the tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n",
      "tensor(3.)\n",
      "tensor(5.)\n",
      "tensor(5.)\n"
     ]
    }
   ],
   "source": [
    "# All indices starting from 0\n",
    " \n",
    "# Get element at row 1, column 0\n",
    "print(f[1,0])\n",
    "\n",
    "# We can also use the following\n",
    "print(f[1][0])\n",
    " \n",
    "# Similarly for 3D Tensor\n",
    "print(g[1,0,0])\n",
    "print(g[1][0][0])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([3., 5.])\n",
      "tensor([1., 3., 5.])\n",
      "tensor([1., 2.])\n",
      "tensor([2., 4.])\n"
     ]
    }
   ],
   "source": [
    "# If you want to access one entire row in a 2D tensor, the syntax is same as NumPy \n",
    "\n",
    "# All elements \n",
    "print(f[:])\n",
    "\n",
    "# All elements from index 1 to 2 (inclusive) \n",
    "print(c[1:3])\n",
    "\n",
    "# All elements till index 3 (exclusive)\n",
    "print(c[:3])\n",
    "\n",
    "\n",
    "# First row\n",
    "print(f[0,:])\n",
    " \n",
    "# Second column\n",
    "print(f[:,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify data type of elements\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.float32\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "torch.int32\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "int_tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(int_tensor.dtype)\n",
    " \n",
    "# What if we changed any one element to floating point number?\n",
    "int_tensor = torch.tensor([[1,2,3],[4.,5,6]])\n",
    "print(int_tensor.dtype)\n",
    " \n",
    "print(int_tensor)\n",
    "     \n",
    "# This can be overridden as follows\n",
    "int_tensor = torch.tensor([[1,2,3],[4.,5,6]], dtype=torch.int32)\n",
    "print(int_tensor.dtype)\n",
    "\n",
    " \n",
    "print(int_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor to/from Numpy Array \n",
    "\n",
    "Can we convert to/from Pytorch Tensors and Numpy Arrays ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "tensor([[8, 7, 6, 5],\n",
      "        [1, 2, 3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Tensor to Array \n",
    "\n",
    "f_numpy = f.numpy()\n",
    "print(f_numpy)\n",
    "\n",
    "\n",
    "# Array to Tensor \n",
    "\n",
    "h = np.array([[8,7,6,5], [1,2,3,4]])\n",
    "h_tensor = torch.from_numpy(h)\n",
    "\n",
    "print(h_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arithmetic Operations on Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([[ 2,  4,  6],\n",
      "        [ 8, 10, 12],\n",
      "        [14, 16, 18]])\n",
      "tensor([[ 2,  4,  6],\n",
      "        [ 8, 10, 12],\n",
      "        [14, 16, 18]])\n",
      "tensor([[ 3,  6,  9],\n",
      "        [12, 15, 18],\n",
      "        [21, 24, 27]])\n",
      "tensor([[ -2,  -4,  -6],\n",
      "        [ -8, -10, -12],\n",
      "        [-14, -16, -18]])\n",
      "tensor([[ -1,  -4,  -9],\n",
      "        [-16, -25, -36],\n",
      "        [-49, -64, -81]])\n",
      "tensor([[ -30,  -36,  -42],\n",
      "        [ -66,  -81,  -96],\n",
      "        [-102, -126, -150]])\n",
      "tensor([[0, 1, 1],\n",
      "        [2, 2, 3],\n",
      "        [3, 4, 4]])\n",
      "tensor([[-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1]])\n"
     ]
    }
   ],
   "source": [
    "# lets create some tensors \n",
    "tensor1 = torch.tensor([[1,2,3], [4,5,6], [7,8,9] ]) \n",
    "tensor2 = torch.tensor([[-1,-2,-3],[-4,-5,-6],[-7,-8,-9]])\n",
    "\n",
    "\n",
    "# Addition \n",
    "print(tensor1 + tensor2)\n",
    "#OR \n",
    "print(torch.add(tensor1, tensor2))\n",
    "\n",
    "\n",
    "# Subtraction: \n",
    "print(tensor1 - tensor2)\n",
    "# OR \n",
    "print(torch.sub(tensor1, tensor2))\n",
    "\n",
    "\n",
    "# Multiplication:  \n",
    "\n",
    "# Tensor with scalar \n",
    "print(tensor1*3)\n",
    "print(2.5*tensor2)\n",
    "\n",
    "\n",
    "# Tensor with Tensor \n",
    "\n",
    "# Element wise\n",
    "print(tensor1*tensor2)\n",
    "\n",
    "# Matrix Multiplication \n",
    "tensor3 = torch.mm(tensor1, tensor2)\n",
    "print(tensor3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Division: \n",
    "\n",
    "# Tensor with Scalar \n",
    "print(tensor1/2)\n",
    "\n",
    "\n",
    "# Tensor with another Tensor\n",
    "# Elementwise division \n",
    "print(tensor2/tensor1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CPU and GPU Tensors \n",
    "\n",
    "Pytorch has different implementations of Tensor for CPU and GPU. Every tensor can be converted to GPU in order to perform massively parallel, fast computations. All operations that will be performed on the tensor will be carried out using GPU-specific routines that come with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor for CPU\n",
    "tensor_cpu = torch.tensor([[1,2],[3,4],[5,6]], device = 'cpu')\n",
    "\n",
    "# Create a tensor for GPU\n",
    "tensor_gpu = torch.tensor([[1,2],[3,4],[5,6]], device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses CPU RAM\n",
    "tensor_cpu = tensor_cpu * 5\n",
    " \n",
    "# This uses GPU RAM\n",
    "# Focus on GPU RAM Consumption\n",
    "tensor_gpu = tensor_gpu * 5\n",
    "\n",
    "\n",
    "# Move GPU tensor to CPU\n",
    "tensor_gpu_cpu = tensor_gpu.to(device='cpu')\n",
    " \n",
    "# Move CPU tensor to GPU\n",
    "tensor_cpu_gpu = tensor_cpu.to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
